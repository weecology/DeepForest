# Config file for DeepForest pytorch module

# Cpu workers for data loaders
# Dataloaders
workers: 0
devices: auto
accelerator: auto
batch_size: 1
limit_batches: 1.0
persistent_workers: false

# Precision settings
# matmul_precision: 'highest' (default, full precision), 'high' (TF32 on Ampere+), or 'medium' (bfloat16)
matmul_precision: highest
# training_precision: null (default '32-true'), '16-mixed', 'bf16-mixed', '32-true', etc.
training_precision: null

# Model Architecture
architecture: 'retinanet'
backbone: 'resnet50'
num_classes: 1
nms_thresh: 0.05
score_thresh: 0.1

# Set model name to None to initialize from scratch
model:
    name: 'weecology/deepforest-tree'
    revision: 'main'

label_dict:
    Tree: 0

# Pre-processing parameters
path_to_raster:
patch_size: 400
patch_overlap: 0.05
annotations_xml:
rgb_dir:
path_to_rgb:

train:
    # Sanity check annotations on dataset load
    check_annotations: False
    log_root: logs
    csv_file:
    root_dir:

    # Optimizer initial learning rate
    lr: 0.001
    # For some models it's helpful to set a lower
    # backbone learning rate. Default is the same.
    lr_backbone: 0.001
    weight_decay: 0.0

    # Data augmentations for training
    # Augmentations must be a list of augmentation names, or a list
    # of dicts with augmentation names and parameters.
    # Examples:
    # augmentations:
    #   - HorizontalFlip: {p: 0.5}
    #   - Downscale: {scale_min: 0.25, scale_max: 0.75, p: 0.5}
    augmentations:
        - HorizontalFlip: {p: 0.5}
    scheduler:
        type: reduceLROnPlateau
        params:
            # Common parameters
            T_max: 10
            eta_min: 0.00001
            lr_lambda: "0.95 ** epoch"  # For lambdaLR and multiplicativeLR
            step_size: 30  # For stepLR
            gamma: 0.1  # For stepLR, multistepLR, and exponentialLR
            milestones: [50, 100]  # For multistepLR

            # ReduceLROnPlateau parameters (used if type is not explicitly mentioned)
            mode: "min"
            factor: 0.1
            patience: 10
            threshold: 0.0001
            threshold_mode: "rel"
            cooldown: 0
            min_lr: 0
            eps: 0.00000001

    # How many epochs to run for
    epochs: 1
    # Useful debugging flag in pytorch lightning, set to True to get a single batch of training to test settings.
    fast_dev_run: False
    # preload images to GPU memory for fast training. This depends on GPU size and number of images.
    preload_images: False
    freeze_backbone: False
    optimizer: sgd
    auxiliary_loss: false

validation:
    csv_file:
    root_dir:
    preload_images: False
    size:
    batch_size: 1
    workers: 0

    # For retinanet you may prefer val_classification, but the default val_loss
    # should work with all models
    lr_plateau_target: val_loss

    # Intersection over union evaluation
    iou_threshold: 0.4
    val_accuracy_interval: 20

    # Data augmentation is none by default for validation, but you can specify:
    # augmentations:
    # if you need to apply augmentations during the val stage.

predict:
    pin_memory: False
