{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with deepforest data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hi all, welcome to another installment of working with DeepForest. Today we have some great data from Australian Eucalyptus forests. Let's walk through the steps to get some predictions. The first thing I did was look at the tile in QGIS to get a sense of the resolution (5cm), habitat type and image quality. Then I started with our standard boilerplate DeepForest prediction code from the 'Getting Started' page. In each of the code snippets below, I show the entire code used to create the output, which reflects what I'm really doing during debugging, which is trying a set of parameters, viewing the output and re-running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "raises-exception"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.12.7 | packaged by Anaconda, Inc. | (main, Oct  4 2024, 13:17:27) [MSC v.1929 64 bit (AMD64)]\n",
      "NumPy: 1.26.4\n",
      "SciPy: 1.17.0\n",
      "DeepForest: 2.0.0\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'deepforest' has no attribute 'deepforest'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 34\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDeepForest:\u001b[39m\u001b[38;5;124m\"\u001b[39m, deepforest\u001b[38;5;241m.\u001b[39m__version__)\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# -----------------------------------------\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Step 3: Load DeepForest pre-trained model\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# -----------------------------------------\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m model \u001b[38;5;241m=\u001b[39m deepforest\u001b[38;5;241m.\u001b[39mdeepforest()\n\u001b[0;32m     35\u001b[0m model\u001b[38;5;241m.\u001b[39mload_model(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweecology/deepforest-tree\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# load pretrained weights\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDeepForest model loaded.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'deepforest' has no attribute 'deepforest'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import rasterio as rio\n",
    "from matplotlib import pyplot as plt\n",
    "from rasterio.plot import show\n",
    "\n",
    "from deepforest import main, utilities, visualize\n",
    "from deepforest.visualize import plot_results\n",
    "\n",
    "m = main.deepforest()\n",
    "\n",
    "m.load_model(\"weecology/deepforest-tree\")\n",
    "try:\n",
    "    image = m.predict_tile(\n",
    "        path=\"/Users/benweinstein/Downloads/Plot13Ortho.tif\",\n",
    "        patch_size=500,\n",
    "        patch_overlap=0,\n",
    "    )\n",
    "    plot_results(image)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we get some error messages saying that the input raster image has four bands. This is pretty common for data that was exported from tools that create orthomosaics, like AgiSoft and Pix4d. Most programs have a toggle button for turning of the 'alpha channel'. We can use rasterio to open up the image and just select the bands we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'main' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m m \u001b[38;5;241m=\u001b[39m main\u001b[38;5;241m.\u001b[39mdeepforest()\n\u001b[0;32m      2\u001b[0m m\u001b[38;5;241m.\u001b[39mload_model(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweecology/deepforest-tree\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Make into a 3 page, remove alpha channel, and make channels last\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'main' is not defined"
     ]
    }
   ],
   "source": [
    "m = main.deepforest()\n",
    "m.load_model(\"weecology/deepforest-tree\")\n",
    "# Make into a 3 page, remove alpha channel, and make channels last\n",
    "r = rio.open(\"/Users/benweinstein/Downloads/Plot13Ortho.tif\").read()\n",
    "r = r[:3, :, :]\n",
    "r = r.transpose(1, 2, 0)\n",
    "\n",
    "# boxes = m.predict_tile(image=r, patch_size=700, patch_overlap=0.2, iou_threshold=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Its starts to run, but wow that's going to take too long on CPU for me to write this post. On GPU this might only take 2mins, but with a CPU almost an hour according to progress bar. Kill that and let's come back to the full prediction set when we are happy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crop a small portion to work with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = main.deepforest()\n",
    "m.load_model(\"weecology/deepforest-tree\")\n",
    "# Make into a 3 page, remove alpha channel, and make channels last\n",
    "r = rio.open(\"/Users/benweinstein/Downloads/Plot13Ortho.tif\").read()\n",
    "r = r[:3, :, :]\n",
    "r = r.transpose(1, 2, 0)\n",
    "\n",
    "# Grab a portion of image just to test, near the middle\n",
    "r = r[12000:13000, 6000:7000, :]\n",
    "plt.imshow(r)\n",
    "plt.show()\n",
    "\n",
    "# save the image as numpy array\n",
    "cv2.imwrite(\"/Users/benweinstein/Downloads/Plot13Ortho_crop.tif\", r)\n",
    "print(m.config)\n",
    "boxes = m.predict_tile(image=r, patch_size=700, patch_overlap=0.2, iou_threshold=0.5)\n",
    "boxes[\"image_path\"] = \"Plot13Ortho_crop.tif\"\n",
    "gdf = utilities.image_to_geo_coordinates(\n",
    "    boxes, root_dir=\"/Users/benweinstein/Downloads\", flip_y_axis=True\n",
    ")\n",
    "gdf.to_file(\"/Users/benweinstein/Downloads/Plot13Ortho_crop.shp\")\n",
    "\n",
    "plot = visualize.plot_results(results=boxes, image=r)\n",
    "plt.imshow(plot)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a decent start for zero-shot imagery in a new resolutions. Let's try a couple things. To see if we can make it any better without new annotations. We always say that DeepForest is best used as a backbone, and an hour of new annotation on target imagery and gentle finetuning will produce better results than changing.  hyperparameters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make geospatial predictions on the full tile\n",
    "\n",
    "Now that i'm happy with a small crop, I want to make predictions on the entire image. This will take some time. We can do away with the cropping of the image, as well as flipping the y axis, since the coordinates are now in the geospatial projection of the tile.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = main.deepforest()\n",
    "m.load_model(\"weecology/deepforest-tree\")\n",
    "# Make into a 3 page, remove alpha channel, and make channels last\n",
    "r = rio.open(\"/Users/benweinstein/Downloads/Plot13Ortho.tif\").read()\n",
    "r = r[:3, :, :]\n",
    "r = r.transpose(1, 2, 0)\n",
    "\n",
    "# boxes = m.predict_tile(image=r, patch_size=700, patch_overlap=0.2, iou_threshold=0.5)\n",
    "# boxes[\"image_path\"] = \"Plot13Ortho.tif\"\n",
    "# gdf = utilities.boxes_to_shapefile(boxes, root_dir=\"/Users/benweinstein/Downloads\")\n",
    "# gdf.to_file(\"/Users/benweinstein/Downloads/Plot13Ortho.shp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general I would look at this in QGIS, its much easier to zoom. Just for the sake of showing how its done, we can overlay the geospatial predicts on the large image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View geopandas overlayed on image\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "\n",
    "# transpose to channels first and then plot\n",
    "show(np.rollaxis(r, 0, 3), ax=ax)\n",
    "gdf.plot(ax=ax, color=\"red\", alpha=0.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
